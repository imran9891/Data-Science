{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### breast_cancer.data Column Details\n",
    "\n",
    "\n",
    " Attribute Information: (class attribute has been moved to last column)<br>\n",
    "<pre>\n",
    "     Attribute                     Domain\n",
    "   -- -----------------------------------------\n",
    "1. Sample code number            id number\n",
    "2. Clump Thickness               1 - 10\n",
    "3. Uniformity of Cell Size       1 - 10\n",
    "4. Uniformity of Cell Shape      1 - 10\n",
    "5. Marginal Adhesion             1 - 10\n",
    "6. Single Epithelial Cell Size   1 - 10\n",
    "7. Bare Nuclei                   1 - 10\n",
    "8. Bland Chromatin               1 - 10\n",
    "9. Normal Nucleoli               1 - 10\n",
    "10. Mitoses                      1 - 10\n",
    "11. Class:                       (2 for benign, 4 for malignant)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Exercise\n",
    "\n",
    "1) Read the dataset 'breast_cancer.data'<br>\n",
    "2) Remove/handle the null values.<br>\n",
    "3) Rename the column names appropriately as per the attribute info mentioned above<br>\n",
    "4) Based on the general understanding of the dataset, select independent features and dependent feature<br>\n",
    "5) Split the dataset into training and testing dataset with test_size 25%<br>\n",
    "6) Apply Decision Tree Classification and predict the class for the test data.<br>\n",
    "7) Find the confusion matrix, accuracy_score and generate classification_report.<br>\n",
    "8) Apply Random Forest Classification and predict the class for the test data.<br>\n",
    "9) Find the confusion matrix, accuracy_score and generate classification_report.<br>\n",
    "Use Cross Validation appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1   2   3   4   5   6   7   8   9   10\n",
       "0  1000025   5   1   1   1   2   1   3   1   1   2\n",
       "1  1002945   5   4   4   5   7  10   3   2   1   2\n",
       "2  1015425   3   1   1   1   2   2   3   1   1   2\n",
       "3  1016277   6   8   8   1   3   4   3   7   1   2\n",
       "4  1017023   4   1   1   3   2   1   3   1   1   2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Read the dataset 'breast_cancer.data'\n",
    "df = pd.read_csv(\"breast_cancer.data\",header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       699 non-null    int64 \n",
      " 1   1       699 non-null    int64 \n",
      " 2   2       699 non-null    int64 \n",
      " 3   3       699 non-null    int64 \n",
      " 4   4       699 non-null    int64 \n",
      " 5   5       699 non-null    int64 \n",
      " 6   6       699 non-null    object\n",
      " 7   7       699 non-null    int64 \n",
      " 8   8       699 non-null    int64 \n",
      " 9   9       699 non-null    int64 \n",
      " 10  10      699 non-null    int64 \n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 60.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The 7th columns is an object datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Remove/handle the null values.\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No information on missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Rename the column names appropriately as per the attribute info mentioned above\n",
    "df.rename(columns={0:\"Sample code number\",1:\"Clump Thickness\",2:\"Uniformity of Cell Size\",3:\"Uniformity of Cell Shape\"\n",
    "                   ,4:\"Marginal Adhesion\",5:\"Single Epithelial Cell Size\",6:\"Bare Nuclei\",7:\"Bland Chromatin\",\n",
    "                   8:\"Normal Nucleoli\",9:\"Mitoses\",10:\"Class\"},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Bare Nuclei` column contains some \"?\" values so replacing it by \"any arbitrary chosen value\" we can convert the column in the same datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Bare Nuclei\"] = df[\"Bare Nuclei\"].astype(str).replace(\"?\",5).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column                       Non-Null Count  Dtype\n",
      "---  ------                       --------------  -----\n",
      " 0   Sample code number           699 non-null    int64\n",
      " 1   Clump Thickness              699 non-null    int64\n",
      " 2   Uniformity of Cell Size      699 non-null    int64\n",
      " 3   Uniformity of Cell Shape     699 non-null    int64\n",
      " 4   Marginal Adhesion            699 non-null    int64\n",
      " 5   Single Epithelial Cell Size  699 non-null    int64\n",
      " 6   Bare Nuclei                  699 non-null    int64\n",
      " 7   Bland Chromatin              699 non-null    int64\n",
      " 8   Normal Nucleoli              699 non-null    int64\n",
      " 9   Mitoses                      699 non-null    int64\n",
      " 10  Class                        699 non-null    int64\n",
      "dtypes: int64(11)\n",
      "memory usage: 60.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Based on the general understanding of the dataset, select independent features and dependent feature\n",
    "X = df.drop([\"Class\"],axis=1)\n",
    "y = df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((524, 10), (175, 10), (524,), (175,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Split the dataset into training and testing dataset with test_size 25%\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 4, 4, 2, 2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2,\n",
       "       2, 2, 4, 4, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 2, 2, 2,\n",
       "       2, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 4, 2, 2, 4, 2, 2, 2, 4, 2, 2,\n",
       "       4, 4, 2, 4, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 2,\n",
       "       4, 2, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2,\n",
       "       4, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 2, 2, 2,\n",
       "       4, 4, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Apply Decision Tree Classification and predict the class for the test data.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "clf_preds = clf.predict(X_test)\n",
    "clf_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[108   5]\n",
      " [  6  56]]\n",
      "\n",
      "Model Score: 93.71%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.95      0.96      0.95       113\n",
      "           4       0.92      0.90      0.91        62\n",
      "\n",
      "    accuracy                           0.94       175\n",
      "   macro avg       0.93      0.93      0.93       175\n",
      "weighted avg       0.94      0.94      0.94       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Find the confusion matrix, accuracy_score and generate classification_report.\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "conf_mat = confusion_matrix(y_test,clf_preds)\n",
    "print(f\"Confusion Matrix:\\n {conf_mat}\\n\")\n",
    "print(f\"Model Score: {round(100*accuracy_score(y_test,clf_preds),2)}%\\n\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test,clf_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 4, 4, 2, 2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2,\n",
       "       2, 2, 4, 4, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2, 2,\n",
       "       2, 4, 4, 4, 4, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 4, 2, 2, 4, 2, 2, 2, 4, 2, 2,\n",
       "       4, 4, 2, 4, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 2,\n",
       "       4, 2, 2, 2, 4, 4, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2,\n",
       "       4, 2, 2, 4, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 2,\n",
       "       4, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Apply Random Forest Classification and predict the class for the test data.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train,y_train)\n",
    "rf_clf_preds = rf_clf.predict(X_test)\n",
    "rf_clf_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[109   4]\n",
      " [  2  60]]\n",
      "\n",
      "Model Score: 96.57%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.96      0.97       113\n",
      "           4       0.94      0.97      0.95        62\n",
      "\n",
      "    accuracy                           0.97       175\n",
      "   macro avg       0.96      0.97      0.96       175\n",
      "weighted avg       0.97      0.97      0.97       175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. Find the confusion matrix, accuracy_score and generate classification_report.\n",
    "conf_mat_ = confusion_matrix(y_test,rf_clf_preds)\n",
    "print(f\"Confusion Matrix:\\n {conf_mat_}\\n\")\n",
    "print(f\"Model Score: {round(100*accuracy_score(y_test,rf_clf_preds),2)}%\\n\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test,rf_clf_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying Cross Validation for Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ['gini','entropy']\n",
    "max_depth = [None, 2,4,6,8,10,12,14]\n",
    "min_samples_split = [2,4,6,8,10]\n",
    "min_samples_leaf = [1,3,5]\n",
    "max_features = [\"auto\",\"sqrt\",\"log2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For criterion gini score is: 92.42%\n",
      "\n",
      "For criterion entropy score is: 93.28%\n",
      "\n",
      "For max_depth None score is: 92.56%\n",
      "\n",
      "For max_depth 2 score is: 92.71%\n",
      "\n",
      "For max_depth 4 score is: 93.27%\n",
      "\n",
      "For max_depth 6 score is: 92.71%\n",
      "\n",
      "For max_depth 8 score is: 91.99%\n",
      "\n",
      "For max_depth 10 score is: 92.71%\n",
      "\n",
      "For max_depth 12 score is: 92.42%\n",
      "\n",
      "For max_depth 14 score is: 92.71%\n",
      "\n",
      "For min_samples_split 2 score is: 92.13%\n",
      "\n",
      "For min_samples_split 4 score is: 92.56%\n",
      "\n",
      "For min_samples_split 6 score is: 92.13%\n",
      "\n",
      "For min_samples_split 8 score is: 90.27%\n",
      "\n",
      "For min_samples_split 10 score is: 91.13%\n",
      "\n",
      "For min_samples_leaf 1 score is: 92.71%\n",
      "\n",
      "For min_samples_leaf 3 score is: 91.84%\n",
      "\n",
      "For min_samples_leaf 5 score is: 93.28%\n",
      "\n",
      "For max_features auto score is: 92.71%\n",
      "\n",
      "For max_features sqrt score is: 92.28%\n",
      "\n",
      "For max_features log2 score is: 92.27%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "for i in criterion:\n",
    "    score = cross_val_score(estimator=DecisionTreeClassifier(criterion=i),\n",
    "                            X=X,\n",
    "                            y=y,\n",
    "                            cv=5,\n",
    "                            scoring=\"accuracy\")\n",
    "    print(f\"For criterion {i} score is: {round(100*score.mean(),2)}%\\n\")\n",
    "for i in max_depth:\n",
    "    score = cross_val_score(estimator=DecisionTreeClassifier(max_depth=i),\n",
    "                            X=X,\n",
    "                            y=y,\n",
    "                            cv=5,\n",
    "                            scoring=\"accuracy\")\n",
    "    print(f\"For max_depth {i} score is: {round(100*score.mean(),2)}%\\n\")\n",
    "for i in min_samples_split:\n",
    "    score = cross_val_score(estimator=DecisionTreeClassifier(min_samples_split=i),\n",
    "                            X=X,\n",
    "                            y=y,\n",
    "                            cv=5,\n",
    "                            scoring=\"accuracy\")\n",
    "    print(f\"For min_samples_split {i} score is: {round(100*score.mean(),2)}%\\n\")\n",
    "for i in min_samples_leaf:\n",
    "    score = cross_val_score(estimator=DecisionTreeClassifier(min_samples_leaf=i),\n",
    "                            X=X,\n",
    "                            y=y,\n",
    "                            cv=5,\n",
    "                            scoring=\"accuracy\")\n",
    "    print(f\"For min_samples_leaf {i} score is: {round(100*score.mean(),2)}%\\n\")\n",
    "for i in max_features:\n",
    "    score = cross_val_score(estimator=DecisionTreeClassifier(max_features=i),\n",
    "                            X=X,\n",
    "                            y=y,\n",
    "                            cv=5,\n",
    "                            scoring=\"accuracy\")\n",
    "    print(f\"For max_features {i} score is: {round(100*score.mean(),2)}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the features with best accuracy and applying the model.fit with selected parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=2, max_features='auto',\n",
       "                       min_samples_leaf=5, min_samples_split=4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(criterion=\"entropy\",\n",
    "               max_depth=2,\n",
    "               min_samples_split=4,\n",
    "               min_samples_leaf=5,\n",
    "               max_features=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying cross validation on RandomForestClassifer model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap = [True,False]\n",
    "criterion = ['gini','entropy']\n",
    "max_depth = [None,2,4,6,8,10]\n",
    "max_features = ['auto','sqrt','log2']\n",
    "min_samples_leaf = [1,3,5,7]\n",
    "min_samples_split = [2,4,6,8]\n",
    "n_estimators = [100,150,200,300,500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For bootstrap True score is: 96.28%\n",
      "\n",
      "For bootstrap False score is: 95.71%\n",
      "\n",
      "For criterion gini score is: 96.14%\n",
      "\n",
      "For criterion entropy score is: 95.57%\n",
      "\n",
      "For max_depth None score is: 96.14%\n",
      "\n",
      "For max_depth 2 score is: 96.28%\n",
      "\n",
      "For max_depth 4 score is: 96.43%\n",
      "\n",
      "For max_depth 6 score is: 96.43%\n",
      "\n",
      "For max_depth 8 score is: 96.0%\n",
      "\n",
      "For max_depth 10 score is: 96.0%\n",
      "\n",
      "For max_features auto score is: 96.14%\n",
      "\n",
      "For max_features sqrt score is: 96.57%\n",
      "\n",
      "For max_features log2 score is: 96.28%\n",
      "\n",
      "For min_samples_leaf 1 score is: 96.0%\n",
      "\n",
      "For min_samples_leaf 3 score is: 96.43%\n",
      "\n",
      "For min_samples_leaf 5 score is: 96.43%\n",
      "\n",
      "For min_samples_leaf 7 score is: 96.57%\n",
      "\n",
      "For min_samples_split 2 score is: 95.71%\n",
      "\n",
      "For min_samples_split 4 score is: 96.28%\n",
      "\n",
      "For min_samples_split 6 score is: 96.28%\n",
      "\n",
      "For min_samples_split 8 score is: 96.28%\n",
      "\n",
      "For n_estimators 100 score is: 96.14%\n",
      "\n",
      "For n_estimators 150 score is: 96.14%\n",
      "\n",
      "For n_estimators 200 score is: 96.28%\n",
      "\n",
      "For n_estimators 300 score is: 96.14%\n",
      "\n",
      "For n_estimators 500 score is: 96.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in bootstrap:\n",
    "    score = cross_val_score(estimator=RandomForestClassifier(bootstrap=i),\n",
    "                            X=X,\n",
    "                            y=y,\n",
    "                            cv=5,\n",
    "                            scoring=\"accuracy\")\n",
    "    print(f\"For bootstrap {i} score is: {round(100*score.mean(),2)}%\\n\")\n",
    "for i in criterion:\n",
    "    score = cross_val_score(estimator=RandomForestClassifier(criterion=i),\n",
    "                            X=X,\n",
    "                            y=y,\n",
    "                            cv=5,\n",
    "                            scoring=\"accuracy\")\n",
    "    print(f\"For criterion {i} score is: {round(100*score.mean(),2)}%\\n\")\n",
    "for i in max_depth:\n",
    "    score = cross_val_score(estimator=RandomForestClassifier(max_depth=i),\n",
    "                            X=X,\n",
    "                            y=y,\n",
    "                            cv=5,\n",
    "                            scoring=\"accuracy\")\n",
    "    print(f\"For max_depth {i} score is: {round(100*score.mean(),2)}%\\n\")\n",
    "for i in max_features:\n",
    "    score = cross_val_score(estimator=RandomForestClassifier(max_features=i),\n",
    "                            X=X,\n",
    "                            y=y,\n",
    "                            cv=5,\n",
    "                            scoring=\"accuracy\")\n",
    "    print(f\"For max_features {i} score is: {round(100*score.mean(),2)}%\\n\")\n",
    "for i in min_samples_leaf:\n",
    "    score = cross_val_score(estimator=RandomForestClassifier(min_samples_leaf=i),\n",
    "                            X=X,\n",
    "                            y=y,\n",
    "                            cv=5,\n",
    "                            scoring=\"accuracy\")\n",
    "    print(f\"For min_samples_leaf {i} score is: {round(100*score.mean(),2)}%\\n\")\n",
    "for i in min_samples_split:\n",
    "    score = cross_val_score(estimator=RandomForestClassifier(min_samples_split=i),\n",
    "                            X=X,\n",
    "                            y=y,\n",
    "                            cv=5,\n",
    "                            scoring=\"accuracy\")\n",
    "    print(f\"For min_samples_split {i} score is: {round(100*score.mean(),2)}%\\n\")\n",
    "for i in n_estimators:\n",
    "    score = cross_val_score(estimator=RandomForestClassifier(n_estimators=i),\n",
    "                            X=X,\n",
    "                            y=y,\n",
    "                            cv=5,\n",
    "                            scoring=\"accuracy\")\n",
    "    print(f\"For n_estimators {i} score is: {round(100*score.mean(),2)}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the features with best accuracy and applying the model.fit with selected parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, max_features='sqrt', min_samples_leaf=7,\n",
       "                       min_samples_split=4, n_estimators=200)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.set_params(bootstrap=True,\n",
    "                  criterion=\"gini\",\n",
    "                  max_depth=4,\n",
    "                  max_features=\"sqrt\",\n",
    "                  min_samples_leaf=7,\n",
    "                  min_samples_split=4,\n",
    "                  n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9542857142857143"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(X_train,y_train)\n",
    "rf_clf.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
